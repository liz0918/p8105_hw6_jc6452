---
title: "Homework 6"
output: github_document
---

```{r library import, echo = FALSE, message = FALSE}
library(tidyverse)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

library(modelr)
library(purrr)
```
## Problem 1
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
set.seed(1)

bootstrap_weather = 
  weather_df %>%   
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin, data = df)),
    results = map(models, broom::tidy),
    fit = map(models, broom::glance))
```

```{r}
bootstrap_results = 
  bootstrap_weather%>%
  unnest(results) %>% 
  select(term, estimate, fit) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(
    log_betas = log(`(Intercept)`* tmin)
  ) %>% 
  unnest(fit) %>% 
  select(log_betas, adj.r.squared)
```
## Plotting distribution of the estimate
```{r}
bootstrap_results %>% 
  ggplot(aes(x = adj.r.squared)) + 
  geom_histogram() + 
  labs(
    title = "Distribution of adjusted R-squared",
    x = "Adjusted R Squared",
    y = "Frequency"
  )

bootstrap_results %>% 
  ggplot(aes(x = log_betas)) +
  geom_histogram()+
  labs(
    title = "Distribution of log (B0 * B1)",
    x = "log (B0 * B1)",
    y = "Frequency"
  )
```
We can observe that both of the plots, the adjusted R-squared and the log (B0 * B1) demonstrate normal distributions. 

```{r}
bootstrap_results %>%
  summarize(
    ci_lower_r2 = quantile(adj.r.squared, 0.025), 
    ci_upper_r2 = quantile(adj.r.squared, 0.975),
    ci_lower_betas = quantile(log_betas, 0.025), 
    ci_upper_betas = quantile(log_betas, 0.975)
  ) %>% 
  unite("adjusted R_squared confidence interval", ci_lower_r2:ci_upper_r2, sep = ", ") %>% 
  unite("log product of betas confidence interval", ci_lower_betas:ci_upper_betas, sep = ", ") %>% 
  knitr::kable()
```
## Problem 2

```{r}
homicide = read.csv("data/homicide-data.csv") %>% 
  unite("city_state", city:state, sep = ', ', na.rm = TRUE) %>% 
  mutate(
    city_state = str_replace(city_state, "Milwaukee, wI", "Milwaukee, WI"),
    victim_age = as.numeric(victim_age),
    unsolved = ifelse(disposition == c("Closed without arrest", "Open/No arrest"), 0, 1)
  ) %>% 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  ) 
```

## glm fpr Baltimore
```{r}
baltimore =
  homicide %>% 
  filter(city_state == "Baltimore, MD") 

baltimore_glm = 
  baltimore %>% 
  glm(unsolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    OR = exp(estimate),
    CI_low = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)) %>% 
  select(term, log_OR = estimate, OR, CI_low, CI_upper) %>% 
  knitr::kable(digits = 3)

```
## each cities
```{r}
glm_city = function(df) {
    glm(unsolved ~ victim_age + victim_race + victim_sex, data =df, family = binomial()) %>%
    broom::tidy() %>%
    mutate(
    OR = exp(estimate),
    CI_low = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
    )
}

city_state_glm = 
  homicide %>% 
  select(city_state, unsolved, victim_race, victim_age, victim_sex) %>% 
  nest(data = unsolved:victim_sex) %>% 
  mutate(
    glm_result = map(data,glm_city)
    ) %>%
  unnest(glm_result) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state,OR, CI_low, CI_upper)

city_state_glm %>% 
  knitr::kable(digits = 3)
```
## Plotting Oddds Ratio of Each City State 
```{r}
city_state_glm %>% 
  ggplot(aes(x= reorder(city_state, OR), y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin= CI_low, max = CI_upper)) +
  theme(
    axis.text.x = element_text(angle = 90, vjust =1, hjust = 1, size = 8)) +
  labs(
    title = "Odds Ratio for each City State with Confidence Intervals",
    x = "City State",
    y = "Odds Ratio"
  )
```

# Problem 3
```{r}
birthweight = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, labels = c("Male", "Female"), levels = c(1,2)),
    frace = factor(frace, labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown"), levels = c(1,2,3,4,8,9)),
    malform = factor(malform, labels = c("absent", "present"), levels = c(0,1)),
    mrace = factor(mrace, labels= c("White", "Black", "Asian", "Puerto Rican", "Other"), levels = c(1,2,3,4,8))
  )

sum(is.na(birthweight))
```
Based on this result, `r sum(is.na(birthweight))`,all the values seem to be present.

## My birthweight model
```{r}
birthweight_lm = 
  birthweight %>% 
  lm(bwt ~babysex + bhead + blength + ppbmi +  gaweeks + momage + delwt, data = .)
summary(birthweight_lm)
```
The summary of the linear model suggests that all the variables selected were statistically significant predictors of `birthweight.` The adjusted R-squared demonstrates to be 0.7012. 

```{r}
birthweight = 
  birthweight %>% 
  modelr::add_predictions(birthweight_lm) %>% 
  modelr::add_residuals(birthweight_lm)
```

```{r}
birthweight %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_smooth() +
  labs(
    title = "Resduals vs. Predicted Values for My Model",
    x = "Predicted Values", 
    y = "Residuals"
  )
```

#comparing my moel to main effects and other models
```{r}
main_effects =
  birthweight %>% 
  lm(bwt ~ blength +gaweeks, data = .)

three_way_interaction = 
  birthweight %>% 
  lm(bwt ~ bhead * blength * babysex, data =. )

summary(main_effects)
summary(three_way_interaction)
```
# comparison between my model and other models via corss-validated prediction error
```{r}
cv = 
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
cv_results = 
  cv %>% 
  mutate(
    my_model = map(train, \(df) lm(bwt ~babysex + bhead + blength + ppbmi +  gaweeks + momage + delwt, data = df)),
    main_effect_model = map(train, \(df) lm(bwt ~ blength +gaweeks, data = df)),
    three_way_interaction_model = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data =df))
  ) %>% 
  mutate(
    my_model_rmse = map2_dbl(my_model, test, rmse),
    main_effect_rmse = map2_dbl(main_effect_model, test, rmse),
    three_way_interaction_rmse = map2_dbl(three_way_interaction_model, test, rmse)
  )
```
#RMSE comparison of the different models
```{r}
cv_results %>% 
  select(contains("rmse")) %>% 
  pivot_longer(everything(),
               names_to = "model",
               values_to = "rmse",
               names_prefix = "rmse ") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()+
  labs(
    title = "3 Model comparison via RMSE",
    x = "Model Type",
    y = "RMSE"
  )
```

Through the violin plot, we can observe that the `main_effect_model` demonstrates the highest RMSE, indicating poor fit. `my_model` suggests to have the lowest RMSE, though it is not a significantly different from `three_way_interaction_model`. 
